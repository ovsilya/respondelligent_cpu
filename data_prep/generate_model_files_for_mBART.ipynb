{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script takes a pickled pandas DF and applies preprocessing transformations to prepare input files for training an mBART model.\n",
    "\n",
    "---\n",
    "UPDATED 03.06.2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/storage/clwork/users/kew/INSTALLS/anaconda3/envs/respondelligent/lib/python3.8/site-packages/tqdm/std.py:670: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Dict, Optional, Tuple\n",
    "import csv\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import json\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from utils_pkg import multiprocessing_utils as mp\n",
    "from utils_pkg import sentiment_utils as svec\n",
    "from utils_pkg.greetings_flair import mask_greetings_and_salutations_in_spacy_doc, mask_greetings_and_salutations\n",
    "from utils_pkg.mask_entities_in_df_texts import mask_entity_tokens\n",
    "from utils_pkg.spacy_utils import add_special_tokens_to_tokenizer\n",
    "\n",
    "pd.options.display.max_columns = 999\n",
    "\n",
    "import spacy\n",
    "\n",
    "from flair.models import SequenceTagger\n",
    "import sentencepiece as sp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup path variables\n",
    "\n",
    "**NOTE** these should be changed to match your operating system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "respo_data = '/home/user/kew/readvisor_proj/CLFILES_readvisor/respondelligent/2021_06/processed/respo_data.pkl'\n",
    "establ_labels = '/home/user/kew/readvisor_proj/CLFILES_readvisor/respondelligent/2021_06/processed/re_establ_name_ids.txt'\n",
    "outdir = '/srv/scratch6/kew/mbart/hospo_respo/respo_final/2021_06/data/'\n",
    "flair_model = './models/ml_grt_slt_flair_multi_fast/best-model.pt'\n",
    "en_spacy_model = './models/spacy/readvisor_in_domain_ner/en_core_web_md-2.3.1'\n",
    "de_spacy_model = './models/spacy/readvisor_in_domain_ner/de_core_news_md-2.3.0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup processing variables\n",
    "\n",
    "Here we set processing options (e.g. whether or not to mask greetings (recommended!))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing variables\n",
    "RANDOM_SEED = 1247\n",
    "lang = 'ml' # ml = multilingual (for mBART)\n",
    "split_col = 'split_imrg_compat' # use this instead of old `split`!!!\n",
    "n_cores = 32 # number of cores for parallel processing\n",
    "do_mask_greetings = True # take approx. an hour to process ~20K items in df\n",
    "apply_lowercase = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# helper functions\n",
    "##################\n",
    "\n",
    "def assign_splits(df):\n",
    "    \"\"\"\n",
    "    expects a shuffled dataframe so na√Øvely populated a new split column based on position\n",
    "    top 10% = test\n",
    "    mid 10% = valid\n",
    "    end 80% = train\n",
    "    \"\"\"\n",
    "    total = len(df)\n",
    "    test = ['test'] * (int(total * .05))\n",
    "    valid = ['valid'] * (int(total * .05))\n",
    "    train = ['train'] * (total-(len(test)+len(valid)))\n",
    "    split_labels = test + valid + train \n",
    "    assert len(df) == len(split_labels)\n",
    "    df['split'] = split_labels\n",
    "    return df\n",
    "    \n",
    "\n",
    "def get_detailed_info_on_df(df, split_col):\n",
    "    print(f'DF has {len(df)} entries')\n",
    "    print('DF COLS:', df.columns)\n",
    "    print(df.groupby('source')[split_col].value_counts())\n",
    "    print(df[split_col].value_counts()) \n",
    "    df.head()\n",
    "    return\n",
    "\n",
    "def token_count(string):\n",
    "    tokens = string.split()\n",
    "    return len(tokens)\n",
    "\n",
    "def ensure_no_split_overlap(df, column_a, column_b, split_col):\n",
    "    \"\"\"\n",
    "    Use this function to ensure no overlap between train / test / dev splits.\n",
    "    \n",
    "    Duplicates can appear after removing greetings/salutations and apply bpe\n",
    "    \"\"\"\n",
    "    print('CHECKING FOR DUPLICATES IN COLS:', column_a, column_b)\n",
    "    \n",
    "    train_src = df[df[split_col] == 'train'][column_a].to_list()\n",
    "    train_tgt = df[df[split_col] == 'train'][column_b].to_list()\n",
    "    \n",
    "    test_src = df[df[split_col] == 'test'][column_a].to_list()\n",
    "    test_tgt = df[df[split_col] == 'test'][column_b].to_list()\n",
    "    \n",
    "    valid_src = df[df[split_col] == 'valid'][column_a].to_list()\n",
    "    valid_tgt = df[df[split_col] == 'valid'][column_b].to_list()\n",
    "    \n",
    "    train = set(zip(train_src, train_tgt))\n",
    "    test = set(zip(test_src, test_tgt))\n",
    "    valid = set(zip(valid_src, valid_tgt))\n",
    "    print('TRAIN', len(train))\n",
    "    print('TEST', len(test))\n",
    "    print('VALID', len(valid))\n",
    "    print('-----------------')\n",
    "    tt = train.intersection(test)\n",
    "    tv = train.intersection(valid)\n",
    "    testv = test.intersection(valid)\n",
    "    if (len(tt) != 0) or (len(tv) != 0) or (len(testv) != 0):\n",
    "        print('WARNING: FOUND OVERLAP IN')\n",
    "        print('\\tTRAIN / TEST:', len(tt))\n",
    "        print('\\tTRAIN / VALID:', len(tv))\n",
    "        print('\\tTEST / VALID:', len(testv))\n",
    "    else:\n",
    "        print('NO OVERLAP FOUND!')\n",
    "    return df\n",
    "\n",
    "def ensure_no_empty_strings(df, column_a, column_b):\n",
    "    print('REMOVING EMPTY STRING VALUES FROM DF WITH LENGTH:', len(df))\n",
    "    df = df[(df[column_a] != '') & (df[column_b] != '')]\n",
    "    print('REMOVED ITEMS DF LENGTH:', len(df))\n",
    "    return df\n",
    "    \n",
    "def write_file(series, outfile):\n",
    "    with open(outfile, 'w', encoding='utf8') as f:\n",
    "        for line in series.to_list():\n",
    "            f.write(f'{line}\\n')\n",
    "    return\n",
    "\n",
    "def write_length_file(series, outfile):\n",
    "    with open(outfile, 'w', encoding='utf8') as f:\n",
    "        for x in series.to_list():\n",
    "            f.write(f'{x:.2f}\\n')\n",
    "    return\n",
    "\n",
    "def write_np_arrays_file(series, outfile):\n",
    "    with open(outfile, 'w', encoding='utf8') as f:\n",
    "        for x in series.to_list():\n",
    "            f.write(f'{\" \".join(map(str, x))}\\n')\n",
    "    return\n",
    "\n",
    "def get_column_stats(df, col):\n",
    "    \n",
    "    uniq_vals = df[col].unique()\n",
    "    print()\n",
    "    print(f'Column `{col}` has {len(uniq_vals)} unique values: e.g.:', list(uniq_vals[:10]))\n",
    "\n",
    "def mask_greetings_and_salutations_in_raw_string_EN(text):\n",
    "    doc = en_nlp(text, disable=[\"tok2vec\", \"tagger\", \"parser\", \"attribute_ruler\", \"lemmatizer\"])\n",
    "    return mask_greetings_and_salutations_in_spacy_doc(doc, tagger)\n",
    "\n",
    "def mask_greetings_and_salutations_in_raw_string_DE(text):\n",
    "    doc = de_nlp(text, disable=[\"tok2vec\", \"tagger\", \"parser\", \"attribute_ruler\", \"lemmatizer\"])\n",
    "    return mask_greetings_and_salutations_in_spacy_doc(doc, tagger)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data prep for mBART model inputs \n",
    " \n",
    "Below we apply the following steps:\n",
    "   - mask greetings and salutations\n",
    "   - add brackets to rating\n",
    "   - add brackets to domain\n",
    "   - replace the `---SEP---` token used to demarkate title/text boundaries with a more explicit and consistent label e.g. `<endtitle>`\n",
    "   - add establishment labels\n",
    "   - write train/test/valid split files required as input to single column tsv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading tagger model...\n",
      "2021-06-07 09:51:26,248 loading file /srv/scratch2/kew/flair_resources/taggers/ml_grt_slt_flair_multi_fast/best-model.pt\n"
     ]
    }
   ],
   "source": [
    "# load in models for processing grettings and salutations\n",
    "print('loading tagger model...')\n",
    "tagger = SequenceTagger.load(flair_model) \n",
    "en_nlp = spacy.load(en_spacy_model)\n",
    "de_nlp = spacy.load(de_spacy_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52028\n",
      "Index(['reviewid', 'grpid', 'domain', 'platformid_rev', 'rating', 'url',\n",
      "       'platformrating', 'review_author', 'response_author', 'review_clean',\n",
      "       'response_clean', 'lang', 'source', 'establishment'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "platform    29564\n",
       "re          22464\n",
       "Name: source, dtype: Int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in data\n",
    "df = pd.read_pickle(respo_data)\n",
    "print(len(df))\n",
    "print(df.columns)\n",
    "\n",
    "df['source'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid respondelligent responses: 22464\n",
      "valid respondelligent responses: 22464\n",
      "valid respondelligent responses: 22464\n",
      "valid English responses: 9686\n",
      "valid German responses: 12778\n"
     ]
    }
   ],
   "source": [
    "# select only respondelligent sources!\n",
    "# NOTE: source=platform are not always written by respondelligent and introduce noise so leave them behind\n",
    "df = df[df['source'] == 're']\n",
    "print(f'valid respondelligent responses: {len(df)}')\n",
    "# ensure no empty values\n",
    "df = df[df['review_clean'] != '']\n",
    "print(f'valid respondelligent responses: {len(df)}')\n",
    "df = df[df['response_clean'] != '']    \n",
    "print(f'valid respondelligent responses: {len(df)}')\n",
    "\n",
    "# subset data by lang\n",
    "df_en = df[df['lang'] == 'en']\n",
    "print(f'valid English responses: {len(df_en)}')\n",
    "df_de = df[df['lang'] == 'de']\n",
    "print(f'valid German responses: {len(df_de)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review-response pair distribution for German:\n",
      "Restaurant    11336\n",
      "Hotel          1442\n",
      "Name: domain, dtype: int64\n",
      "\n",
      "Review-response pair distribution for English:\n",
      "Restaurant    7412\n",
      "Hotel         2274\n",
      "Name: domain, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Review-response pair distribution for German:')\n",
    "print(df[df.lang == 'de'].domain.value_counts())\n",
    "print()\n",
    "print('Review-response pair distribution for English:')\n",
    "print(df[df.lang == 'en'].domain.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs on 32 CPU(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9686/9686 [21:22<00:00,  7.55it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 1284.27 seconds\n",
      "Running jobs on 32 CPU(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-d94e66211408>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_en['response_clean'] = en_responses\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12778/12778 [25:29<00:00,  8.36it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 1530.67 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-d94e66211408>:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_de['response_clean'] = de_responses\n"
     ]
    }
   ],
   "source": [
    "# apply greeting masks\n",
    "# NOTE: this takes approx 20 mins to do 10K examples, so go make a coffee...\n",
    "if do_mask_greetings:\n",
    "    en_responses = df_en['response_clean'].tolist()\n",
    "    en_responses = mp.parallelise(mask_greetings_and_salutations_in_raw_string_EN, en_responses, n_cores)\n",
    "    assert len(en_responses) == len(df_en)\n",
    "    df_en['response_clean'] = en_responses\n",
    "\n",
    "    de_responses = df_de['response_clean'].tolist()\n",
    "    de_responses = mp.parallelise(mask_greetings_and_salutations_in_raw_string_DE, de_responses, n_cores)\n",
    "    assert len(de_responses) == len(df_de)\n",
    "    df_de['response_clean'] = de_responses\n",
    "\n",
    "df = pd.concat([df_en, df_de])\n",
    "# shuffle dataset\n",
    "df = df.sample(frac=1, random_state=RANDOM_SEED)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49249    <GREETING> Vielen Dank f√ºr Dein Feedback, dass...\n",
       "367      <GREETING> erstes m√∂chten wir uns bei Ihnen f√º...\n",
       "25010    <GREETING> Thank you for taking the time to gi...\n",
       "23403    <GREETING> m√∂chten wir uns bei Ihnen bedanken,...\n",
       "16792    <GREETING> Thank you for choosing one of our s...\n",
       "                               ...                        \n",
       "22710    <GREETING> Thank you for your outstanding revi...\n",
       "39390    <GREETING> Als erstes m√∂chten wir uns bei Ihne...\n",
       "12291    <GREETING> Thank you for your visit and for ta...\n",
       "2520     <GREETING> It's great to hear back from you, t...\n",
       "33357    <GREETING> Wir freuen uns sehr, dass wir Sie a...\n",
       "Name: response_clean, Length: 22464, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect results\n",
    "df['response_clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF has 22464 entries\n",
      "DF COLS: Index(['reviewid', 'grpid', 'domain', 'platformid_rev', 'rating', 'url',\n",
      "       'platformrating', 'review_author', 'response_author', 'review_clean',\n",
      "       'response_clean', 'lang', 'source', 'establishment', 'split'],\n",
      "      dtype='object')\n",
      "source  split\n",
      "re      train    20218\n",
      "        test      1123\n",
      "        valid     1123\n",
      "Name: split, dtype: int64\n",
      "train    20218\n",
      "test      1123\n",
      "valid     1123\n",
      "Name: split, dtype: int64\n",
      "\n",
      "CHECKING FOR DUPLICATES IN COLS: review_clean response_clean\n",
      "TRAIN 20216\n",
      "TEST 1123\n",
      "VALID 1123\n",
      "-----------------\n",
      "NO OVERLAP FOUND!\n",
      "\n",
      "\n",
      "Column `rating` has 7 unique values: e.g.: [4, 2, 1, 5, 3, -1, -2]\n",
      "\n",
      "Column `domain` has 2 unique values: e.g.: ['Restaurant', 'Hotel']\n",
      "\n",
      "Column `source` has 1 unique values: e.g.: ['re']\n",
      "\n",
      "Column `establishment` has 113 unique values: e.g.: ['bank-zuerich', 'santa-lucia oerlikon-zuerich', 'hotel-city-zuerich', 'odeon-zuerich', 'leoneck-swiss-hotel-zurich', 'amalfi-zuerich', 'spaghetti-factory-chindlifraesser-bern', 'swiss-chuchi-zuerich', 'santa-lucia niederdorf-zuerich', 'hotel nidwaldnerhof-beckenried']\n"
     ]
    }
   ],
   "source": [
    "# when processing data from re:spondelligent DBs,\n",
    "# split information based on IDs is not available, \n",
    "# so here we simply create new splits. \n",
    "# NOTE: for better reproducibility, between data versions, \n",
    "# a dedicated test set should be developed based on reviewids in re:spondelligent's DB\n",
    "if not split_col in df.columns:\n",
    "    df = assign_splits(df)\n",
    "    split_col = 'split'\n",
    "\n",
    "# inspect DF\n",
    "get_detailed_info_on_df(df, split_col)\n",
    "print()\n",
    "ensure_no_split_overlap(df, 'review_clean', 'response_clean', split_col)\n",
    "print()\n",
    "get_column_stats(df, 'rating')\n",
    "get_column_stats(df, 'domain')\n",
    "get_column_stats(df, 'source')\n",
    "get_column_stats(df, 'establishment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5    11945\n",
      " 4     5586\n",
      " 3     2176\n",
      " 1     1251\n",
      " 2     1074\n",
      "-1      407\n",
      "-2       25\n",
      "Name: rating, dtype: Int64\n",
      "5    11945\n",
      "4     5586\n",
      "3     2176\n",
      "1     1683\n",
      "2     1074\n",
      "Name: rating, dtype: Int64\n"
     ]
    }
   ],
   "source": [
    "# map all negative rating values to 1\n",
    "print(df['rating'].value_counts())\n",
    "df.loc[df['rating'] < 1, 'rating'] = 1\n",
    "print(df['rating'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<est_3>      1846\n",
       "<est_5>       912\n",
       "<est_6>       877\n",
       "<est_2>       794\n",
       "<est_10>      587\n",
       "             ... \n",
       "<est_86>       12\n",
       "<est_179>      11\n",
       "<est_201>      10\n",
       "<est_0>         7\n",
       "<est_37>        4\n",
       "Name: establishment_cat, Length: 112, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here, we load the predefined mapping between establishments and their labels for the model.\n",
    "# NOTE: to generate the labels for a particular model, \n",
    "# see collect_establishment_occurence_freq_counts_from_respondelligent_data.py,\n",
    "# which labels establishments according to collected frequency counts\n",
    "# and produces the establ_labels tsv file\n",
    "\n",
    "estabs = {}\n",
    "if establ_labels:\n",
    "    with open(establ_labels, 'r', encoding='utf8') as inf:\n",
    "        for line in inf:\n",
    "            line = line.rstrip().split('\\t')\n",
    "            estabs[line[0]] = (int(line[1]), line[2], line[3])\n",
    "\n",
    "def map_establishments_to_labels_based_on_freq_counts(name, estabs=estabs, threshold=10):\n",
    "    \"\"\"\n",
    "    Fetches appropriate establishment label for a given restaurant/hotel name.\n",
    "    If the occurence frequency of the restauarant/hotel in the training data is lower\n",
    "    than the specifies threshold, we return a catch-all placeholder label. This ensure that\n",
    "    the model can generalise to infrequent/new customers.\n",
    "    \"\"\"\n",
    "    freq, hum_label, cat_label = estabs.get(name, (0, '<unk_est>', '<est_0>'))\n",
    "    if freq >= threshold:\n",
    "        return cat_label\n",
    "    else:\n",
    "        return '<est_0>'\n",
    "\n",
    "df['establishment_cat'] = df['establishment'].apply(lambda x: map_establishments_to_labels_based_on_freq_counts(x))\n",
    "df.establishment_cat.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duplicate src and ttgt texts (as  a backup in case a mistake was made - save re-doing mask greetings!)\n",
    "df['review'] = df['review_clean']\n",
    "df['response'] = df['response_clean']\n",
    "\n",
    "# convert raw categorical values to 'special token' labels\n",
    "df['domain'] = '<' + df['domain'].str.lower() + '>'\n",
    "# cast int to string in order to add < and >\n",
    "df['rating'] = df['rating'].astype(\"string\")\n",
    "df['rating'] = '<' + df['rating'].str.lower() + '>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace title boundary with more explicit special token\n",
    "df['review'] = df['review'].str.replace('---SEP---', '<endtitle>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add language tags used by mBART\n",
    "mbart_lang_tags = {\n",
    "    'de': 'de_DE',\n",
    "    'en': 'en_XX',\n",
    "    '<de>': 'de_DE',\n",
    "    '<en>': 'en_XX',\n",
    "}    \n",
    "\n",
    "df['mbart_lang_tags'] = df['lang'].apply(lambda x: mbart_lang_tags[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF has 22464 entries\n",
      "DF COLS: Index(['reviewid', 'grpid', 'domain', 'platformid_rev', 'rating', 'url',\n",
      "       'platformrating', 'review_author', 'response_author', 'review_clean',\n",
      "       'response_clean', 'lang', 'source', 'establishment', 'split',\n",
      "       'establishment_cat', 'review', 'response', 'mbart_lang_tags'],\n",
      "      dtype='object')\n",
      "source  split\n",
      "re      train    20218\n",
      "        test      1123\n",
      "        valid     1123\n",
      "Name: split, dtype: int64\n",
      "train    20218\n",
      "test      1123\n",
      "valid     1123\n",
      "Name: split, dtype: int64\n",
      "\n",
      "CHECKING FOR DUPLICATES IN COLS: review response\n",
      "TRAIN 20216\n",
      "TEST 1123\n",
      "VALID 1123\n",
      "-----------------\n",
      "NO OVERLAP FOUND!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# inspect DF\n",
    "get_detailed_info_on_df(df, split_col)\n",
    "print()\n",
    "df = ensure_no_split_overlap(df, 'review', 'response', split_col)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewid</th>\n",
       "      <th>grpid</th>\n",
       "      <th>domain</th>\n",
       "      <th>platformid_rev</th>\n",
       "      <th>rating</th>\n",
       "      <th>url</th>\n",
       "      <th>platformrating</th>\n",
       "      <th>review_author</th>\n",
       "      <th>response_author</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>response_clean</th>\n",
       "      <th>lang</th>\n",
       "      <th>source</th>\n",
       "      <th>establishment</th>\n",
       "      <th>split</th>\n",
       "      <th>establishment_cat</th>\n",
       "      <th>review</th>\n",
       "      <th>response</th>\n",
       "      <th>mbart_lang_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49249</th>\n",
       "      <td>522927</td>\n",
       "      <td>150</td>\n",
       "      <td>&lt;restaurant&gt;</td>\n",
       "      <td>276</td>\n",
       "      <td>&lt;4&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Martin Baiata</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Coole Bar, gerne nochmals</td>\n",
       "      <td>&lt;GREETING&gt; Vielen Dank f√ºr Dein Feedback, dass...</td>\n",
       "      <td>de</td>\n",
       "      <td>re</td>\n",
       "      <td>bank-zuerich</td>\n",
       "      <td>test</td>\n",
       "      <td>&lt;est_20&gt;</td>\n",
       "      <td>Coole Bar, gerne nochmals</td>\n",
       "      <td>&lt;GREETING&gt; Vielen Dank f√ºr Dein Feedback, dass...</td>\n",
       "      <td>de_DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>306422</td>\n",
       "      <td>153</td>\n",
       "      <td>&lt;restaurant&gt;</td>\n",
       "      <td>285</td>\n",
       "      <td>&lt;2&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Karl-Heinz Tepper</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Wir waren am 22.4.19 im Santa Lucia. Die Bedie...</td>\n",
       "      <td>&lt;GREETING&gt; erstes m√∂chten wir uns bei Ihnen f√º...</td>\n",
       "      <td>de</td>\n",
       "      <td>re</td>\n",
       "      <td>santa-lucia oerlikon-zuerich</td>\n",
       "      <td>test</td>\n",
       "      <td>&lt;est_40&gt;</td>\n",
       "      <td>Wir waren am 22.4.19 im Santa Lucia. Die Bedie...</td>\n",
       "      <td>&lt;GREETING&gt; erstes m√∂chten wir uns bei Ihnen f√º...</td>\n",
       "      <td>de_DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25010</th>\n",
       "      <td>526927</td>\n",
       "      <td>461</td>\n",
       "      <td>&lt;hotel&gt;</td>\n",
       "      <td>1750</td>\n",
       "      <td>&lt;1&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>Luiz</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Better before Pandemic ---SEP--- (+) Very cent...</td>\n",
       "      <td>&lt;GREETING&gt; Thank you for taking the time to gi...</td>\n",
       "      <td>en</td>\n",
       "      <td>re</td>\n",
       "      <td>hotel-city-zuerich</td>\n",
       "      <td>test</td>\n",
       "      <td>&lt;est_182&gt;</td>\n",
       "      <td>Better before Pandemic &lt;endtitle&gt; (+) Very cen...</td>\n",
       "      <td>&lt;GREETING&gt; Thank you for taking the time to gi...</td>\n",
       "      <td>en_XX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23403</th>\n",
       "      <td>306442</td>\n",
       "      <td>95</td>\n",
       "      <td>&lt;restaurant&gt;</td>\n",
       "      <td>193</td>\n",
       "      <td>&lt;2&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Leonie Sutter</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Location gut. Bis jetzt fast nur schlechte Erf...</td>\n",
       "      <td>&lt;GREETING&gt; m√∂chten wir uns bei Ihnen bedanken,...</td>\n",
       "      <td>de</td>\n",
       "      <td>re</td>\n",
       "      <td>odeon-zuerich</td>\n",
       "      <td>test</td>\n",
       "      <td>&lt;est_15&gt;</td>\n",
       "      <td>Location gut. Bis jetzt fast nur schlechte Erf...</td>\n",
       "      <td>&lt;GREETING&gt; m√∂chten wir uns bei Ihnen bedanken,...</td>\n",
       "      <td>de_DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16792</th>\n",
       "      <td>259170</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;hotel&gt;</td>\n",
       "      <td>221</td>\n",
       "      <td>&lt;5&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>10</td>\n",
       "      <td>Roshas</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>(+) The suite we had was comfortable, modern a...</td>\n",
       "      <td>&lt;GREETING&gt; Thank you for choosing one of our s...</td>\n",
       "      <td>en</td>\n",
       "      <td>re</td>\n",
       "      <td>leoneck-swiss-hotel-zurich</td>\n",
       "      <td>test</td>\n",
       "      <td>&lt;est_5&gt;</td>\n",
       "      <td>(+) The suite we had was comfortable, modern a...</td>\n",
       "      <td>&lt;GREETING&gt; Thank you for choosing one of our s...</td>\n",
       "      <td>en_XX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewid  grpid        domain  platformid_rev rating   url  \\\n",
       "49249    522927    150  <restaurant>             276    <4>  <NA>   \n",
       "367      306422    153  <restaurant>             285    <2>  <NA>   \n",
       "25010    526927    461       <hotel>            1750    <1>  <NA>   \n",
       "23403    306442     95  <restaurant>             193    <2>  <NA>   \n",
       "16792    259170    100       <hotel>             221    <5>  <NA>   \n",
       "\n",
       "      platformrating      review_author response_author  \\\n",
       "49249           <NA>      Martin Baiata            <NA>   \n",
       "367             <NA>  Karl-Heinz Tepper            <NA>   \n",
       "25010              3               Luiz            <NA>   \n",
       "23403           <NA>      Leonie Sutter            <NA>   \n",
       "16792             10             Roshas            <NA>   \n",
       "\n",
       "                                            review_clean  \\\n",
       "49249                          Coole Bar, gerne nochmals   \n",
       "367    Wir waren am 22.4.19 im Santa Lucia. Die Bedie...   \n",
       "25010  Better before Pandemic ---SEP--- (+) Very cent...   \n",
       "23403  Location gut. Bis jetzt fast nur schlechte Erf...   \n",
       "16792  (+) The suite we had was comfortable, modern a...   \n",
       "\n",
       "                                          response_clean lang source  \\\n",
       "49249  <GREETING> Vielen Dank f√ºr Dein Feedback, dass...   de     re   \n",
       "367    <GREETING> erstes m√∂chten wir uns bei Ihnen f√º...   de     re   \n",
       "25010  <GREETING> Thank you for taking the time to gi...   en     re   \n",
       "23403  <GREETING> m√∂chten wir uns bei Ihnen bedanken,...   de     re   \n",
       "16792  <GREETING> Thank you for choosing one of our s...   en     re   \n",
       "\n",
       "                      establishment split establishment_cat  \\\n",
       "49249                  bank-zuerich  test          <est_20>   \n",
       "367    santa-lucia oerlikon-zuerich  test          <est_40>   \n",
       "25010            hotel-city-zuerich  test         <est_182>   \n",
       "23403                 odeon-zuerich  test          <est_15>   \n",
       "16792    leoneck-swiss-hotel-zurich  test           <est_5>   \n",
       "\n",
       "                                                  review  \\\n",
       "49249                          Coole Bar, gerne nochmals   \n",
       "367    Wir waren am 22.4.19 im Santa Lucia. Die Bedie...   \n",
       "25010  Better before Pandemic <endtitle> (+) Very cen...   \n",
       "23403  Location gut. Bis jetzt fast nur schlechte Erf...   \n",
       "16792  (+) The suite we had was comfortable, modern a...   \n",
       "\n",
       "                                                response mbart_lang_tags  \n",
       "49249  <GREETING> Vielen Dank f√ºr Dein Feedback, dass...           de_DE  \n",
       "367    <GREETING> erstes m√∂chten wir uns bei Ihnen f√º...           de_DE  \n",
       "25010  <GREETING> Thank you for taking the time to gi...           en_XX  \n",
       "23403  <GREETING> m√∂chten wir uns bei Ihnen bedanken,...           de_DE  \n",
       "16792  <GREETING> Thank you for choosing one of our s...           en_XX  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wir waren am 22.4.19 im Santa Lucia. Die Bedienung war sehr gut, freundlich und aufmerksam. Super. Das Essen aber eine Entt√§uschung. Preis/Leistung eine Katastrophe. Wir hatten als Vorspeise einen Salat \"Insalata Santa Lucia\". Die grosse Version f√ºr 19.-Fr. Was wir bekamen empfanden wir als H√§ufchen Elend. F√ºr diesen Preis viel zu wenig und lieblos angerichtet. Laut Karte mit Radieschen. An diese erinnere ich mich gar nicht mehr. Unser Bild Nr. 4 zeigt zwei Salate von Deutschland die zusammen 25 Euro gekostet haben. F√ºr √§hnlichen Preis haben wir etwas bekommen das Herz, Phantasie hat und satt macht. Und das doppelt. Dass es in der Schweiz teurer ist, ist mir ja schon klar. Aber dieser Vergleich empfinden wir als Schande. Die Pizza die ich bestellte war eine Frutti di Mare. Vergleicht mal die Bilder wie ich es im Santa Lucia bekam und wie ich es in Italien bekam. Ja, ist schon klar. Ich kann nicht das gleiche erwarten. Aber wenn ich schon mehr als das doppelte bezahle, sollte dies optisch nicht so krass unterschiedlich sein. Sonst ist ein so massiv h√∂herer Preis nicht gerechtfertigt. Das dritte Bild ist eine andere Pizza aus Italien. Nicht mal halb so teuer und dazu garniert mit Herz und Phantasie. So wie es sein sollte. Das Essen in dieser Pizzeria ist nach unserer Meinung das Geld nicht ann√§hernd wert. Wir sind entsetzt und entt√§uscht. Ich habe mich richtig aufgeregt. Santa Lucia ist schlie√ülich ein Restaurant das sich auf italienische Spezialit√§ten spezialisiert hat. Eine Pizzeria. F√ºr mich ist es aber rein schweizerische Geldmaschine. Einzig die Bedienung war super. Dank an das sehr gute Personal. Komme trotzdem nie wieder! Reihenfolge der Bilder hat sich ge√§ndert: 1. Bild 2 Salat von Deutschland, 2. Bild Pizzas vom Santa Lucia, 3. Bild Frutti Di Mare von Italien, 4. Bild andere Pizza von Italien\n",
      "Wir waren am 22.4.19 im Santa Lucia. Die Bedienung war sehr gut, freundlich und aufmerksam. Super. Das Essen aber eine Entt√§uschung. Preis/Leistung eine Katastrophe. Wir hatten als Vorspeise einen Salat \"Insalata Santa Lucia\". Die grosse Version f√ºr 19.-Fr. Was wir bekamen empfanden wir als H√§ufchen Elend. F√ºr diesen Preis viel zu wenig und lieblos angerichtet. Laut Karte mit Radieschen. An diese erinnere ich mich gar nicht mehr. Unser Bild Nr. 4 zeigt zwei Salate von Deutschland die zusammen 25 Euro gekostet haben. F√ºr √§hnlichen Preis haben wir etwas bekommen das Herz, Phantasie hat und satt macht. Und das doppelt. Dass es in der Schweiz teurer ist, ist mir ja schon klar. Aber dieser Vergleich empfinden wir als Schande. Die Pizza die ich bestellte war eine Frutti di Mare. Vergleicht mal die Bilder wie ich es im Santa Lucia bekam und wie ich es in Italien bekam. Ja, ist schon klar. Ich kann nicht das gleiche erwarten. Aber wenn ich schon mehr als das doppelte bezahle, sollte dies optisch nicht so krass unterschiedlich sein. Sonst ist ein so massiv h√∂herer Preis nicht gerechtfertigt. Das dritte Bild ist eine andere Pizza aus Italien. Nicht mal halb so teuer und dazu garniert mit Herz und Phantasie. So wie es sein sollte. Das Essen in dieser Pizzeria ist nach unserer Meinung das Geld nicht ann√§hernd wert. Wir sind entsetzt und entt√§uscht. Ich habe mich richtig aufgeregt. Santa Lucia ist schlie√ülich ein Restaurant das sich auf italienische Spezialit√§ten spezialisiert hat. Eine Pizzeria. F√ºr mich ist es aber rein schweizerische Geldmaschine. Einzig die Bedienung war super. Dank an das sehr gute Personal. Komme trotzdem nie wieder! Reihenfolge der Bilder hat sich ge√§ndert: 1. Bild 2 Salat von Deutschland, 2. Bild Pizzas vom Santa Lucia, 3. Bild Frutti Di Mare von Italien, 4. Bild andere Pizza von Italien\n",
      "<GREETING> erstes m√∂chten wir uns bei Ihnen f√ºr Ihren Besuch bedanken und dass Sie sich die Zeit f√ºr ein so ausf√ºhrliches Feedback genommen haben. Egal ob online oder vor Ort, wir nehmen bei uns jede G√§ster√ºckmeldung sehr ernst. Es tut uns leid zu h√∂ren, dass wir weder beim Salat noch bei den Pizzen Ihre Erwartungen erf√ºllen konnten, respektive Ihren Geschmack getroffen haben. Wie verstehen, dass gerade bei einer Pizza die Erfahrungen und Geschm√§cker verschieden sind. Wir k√∂nnen Ihnen aber auch versichern, dass unsere Pizzaioli jede Pizza mit Leidenschaft und den besten Zutaten zubereiten - gebacken wird bei uns selbstverst√§ndlich nur im Original Holzofen. Trotzdem m√∂chten wir nat√ºrlich nicht, dass Sie einen so negativen Eindruck von uns haben und w√ºrden es deshalb gerne wieder gutmachen bei Ihnen. K√∂nnten Sie uns daf√ºr bitte Ihre Anschrift und den genauen Zeitpunkt Ihres Besuchs auf social.media@bindella.ch schicken? Wir werden Sie mit unserer Pizza wohl auch bei einer zweiten Chance nicht so richtig gl√ºcklich machen k√∂nnen. Dennoch w√ºrden wir uns √ºber ein Wiedersehen freuen und k√∂nnen Ihnen dann zum Beispiel einen Teller hausgemachte Pasta empfehlen. la vita √® bella - Adrian & Santa-Lucia-Team PS Danke auch f√ºr die Fotos. Wir haben die zur Inspiration gerne mit dem ganzen Team geteilt.\n",
      "<GREETING> erstes m√∂chten wir uns bei Ihnen f√ºr Ihren Besuch bedanken und dass Sie sich die Zeit f√ºr ein so ausf√ºhrliches Feedback genommen haben. Egal ob online oder vor Ort, wir nehmen bei uns jede G√§ster√ºckmeldung sehr ernst. Es tut uns leid zu h√∂ren, dass wir weder beim Salat noch bei den Pizzen Ihre Erwartungen erf√ºllen konnten, respektive Ihren Geschmack getroffen haben. Wie verstehen, dass gerade bei einer Pizza die Erfahrungen und Geschm√§cker verschieden sind. Wir k√∂nnen Ihnen aber auch versichern, dass unsere Pizzaioli jede Pizza mit Leidenschaft und den besten Zutaten zubereiten - gebacken wird bei uns selbstverst√§ndlich nur im Original Holzofen. Trotzdem m√∂chten wir nat√ºrlich nicht, dass Sie einen so negativen Eindruck von uns haben und w√ºrden es deshalb gerne wieder gutmachen bei Ihnen. K√∂nnten Sie uns daf√ºr bitte Ihre Anschrift und den genauen Zeitpunkt Ihres Besuchs auf social.media@bindella.ch schicken? Wir werden Sie mit unserer Pizza wohl auch bei einer zweiten Chance nicht so richtig gl√ºcklich machen k√∂nnen. Dennoch w√ºrden wir uns √ºber ein Wiedersehen freuen und k√∂nnen Ihnen dann zum Beispiel einen Teller hausgemachte Pasta empfehlen. la vita √® bella - Adrian & Santa-Lucia-Team PS Danke auch f√ºr die Fotos. Wir haben die zur Inspiration gerne mit dem ganzen Team geteilt.\n"
     ]
    }
   ],
   "source": [
    "# inspect texts\n",
    "\n",
    "print(df.iloc[1]['review_clean'])\n",
    "print(df.iloc[1]['review'])\n",
    "print(df.iloc[1]['response'])\n",
    "print(df.iloc[1]['response_clean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write output datasets\n",
    "\n",
    "given the names of columns in dict `col_name_outfile_mapping` (keys), produce line-aligned output files for each for the different splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test split has length: 1123\n",
      "valid split has length: 1123\n",
      "train split has length: 20218\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "col_name_outfile_mapping = {\n",
    "    'reviewid': 'id', \n",
    "    'review': 'review', # normal review \n",
    "    'establishment_cat': 'est_label',\n",
    "    'response': 'response',  # normal response\n",
    "    'domain': 'domain', # normal domain\n",
    "    'rating': 'rating', # normal review rating\n",
    "    'establishment': 'establishment', \n",
    "    'source': 'source',\n",
    "    'mbart_lang_tags': 'lang_tags'\n",
    "}\n",
    "\n",
    "def generate_model_files(df,\n",
    "                         outdir: str,\n",
    "                         col_name_outfile_mapping: Dict = col_name_outfile_mapping,\n",
    "                         split_col: str = split_col,\n",
    "                         n: int = 0):\n",
    "    \"\"\"\n",
    "    Generates multiple individual files (one per column).\n",
    "    For each split (train/test/valid) lines in each output file must correspond with each other!\n",
    "    \"\"\"\n",
    "    for split in df[split_col].unique():  \n",
    "\n",
    "        split_df = df[df[split_col] == split]\n",
    "        \n",
    "        # shuffle train set - mainly required after upsampling!\n",
    "        if split == 'train':\n",
    "            split_df = split_df.sample(frac=1, random_state=RANDOM_SEED)\n",
    "        \n",
    "        if n: # just take a head of dataframe\n",
    "            if split == 'train':\n",
    "                split_df = split_df.head(n)\n",
    "            else:\n",
    "                split_df = split_df.head(int(n*0.1))\n",
    "\n",
    "        print(f'{split} split has length: {len(split_df)}')\n",
    "\n",
    "        \n",
    "        for k, v in col_name_outfile_mapping.items():\n",
    "            if k == 'src_len_cates':\n",
    "                write_length_file(split_df[k], outdir / f'{split}.{v}')\n",
    "            elif 'sent_vec' in k:\n",
    "                write_np_arrays_file(split_df[k], outdir / f'{split}.{v}')\n",
    "            else:\n",
    "                write_file(split_df[k], outdir / f'{split}.{v}')\n",
    "        \n",
    "    print('Done!')\n",
    "    return\n",
    "\n",
    "outdir=Path(outdir)\n",
    "outdir.mkdir(parents=True, exist_ok=True)\n",
    "generate_model_files(df, outdir, col_name_outfile_mapping, split_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:respondelligent]",
   "language": "python",
   "name": "conda-env-respondelligent-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
